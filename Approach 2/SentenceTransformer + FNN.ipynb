{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from lightning_fabric import Fabric\n",
    "\n",
    "\n",
    "from utils.config import Parameters\n",
    "from utils.dataset import Dataset\n",
    "from utils.performance_evaluation import performance_evaluation\n",
    "from utils.utils import format_time\n",
    "from utils.logger import init_logger \n",
    "from utils.early_stopping import EarlyStopping\n",
    "from utils.Classifier import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "# When running on the CuDNN backend, two further options must be set\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# Set a fixed value for the hash seed\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "\n",
    "# Setup Fabric\n",
    "fabric = Fabric(accelerator=\"auto\", devices=\"auto\", precision=\"bf16-mixed\", strategy=\"auto\")\n",
    "fabric.launch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parameters\n",
    "args = Parameters()\n",
    "\n",
    "# Project directory\n",
    "if (not os.path.exists(args.output_dir)):\n",
    "    os.mkdir(args.output_dir)\n",
    "\n",
    "# Create logger\n",
    "logger = init_logger(log_file = 'logs.log') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(args.dataset_path, sep='&')\n",
    "df['label'] = df['label'].astype('float')\n",
    "# Split Train/Test datasets\n",
    "df_train, df_test = train_test_split(df, test_size=args.test_size, shuffle=True, stratify=df['label'])\n",
    "# Create validation dataset\n",
    "df_train, df_valid = train_test_split(df_train, test_size=args.valid_size, shuffle=True, stratify=df_train['label'])\n",
    "\n",
    "# Reset indices\n",
    "df_train = df_train.reset_index().drop(['index'], axis=1)\n",
    "df_valid = df_valid.reset_index().drop(['index'], axis=1) \n",
    "df_test = df_test.reset_index().drop(['index'], axis=1)\n",
    "\n",
    "# Class Visualization\n",
    "plt.figure(figsize = (6,2))\n",
    "plt.hist(df_train['label']);\n",
    "plt.hist(df_test['label']);\n",
    "plt.hist(df_valid['label']);\n",
    "\n",
    "plt.legend(['Training', 'Validation', 'Testing'], frameon=False);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Dataloader were created\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "train_dataset = Dataset(df_train)\n",
    "# Create data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.train_batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "valid_dataset = Dataset(df_valid)\n",
    "# Create data loader\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=args.train_batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "test_dataset = Dataset(df_test)\n",
    "# Create data loader\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False)\n",
    "\n",
    "logger.info('Dataloader were created')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Load pretrained SentenceTransformer: lighteternal/stsb-xlm-r-greek-transfer\n"
     ]
    }
   ],
   "source": [
    "from utils.Classifier import Classifier\n",
    "\n",
    "model = Classifier(args=args).to(args.device);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Training parameters were setup\n"
     ]
    }
   ],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "\n",
    "\n",
    "optimizer_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": args.weight_decay,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Setup optimizer\n",
    "if args.optimizer == 'AdamW':\n",
    "    optimizer = torch.optim.AdamW(optimizer_parameters, lr=args.learning_rate)\n",
    "elif args.optimizer == 'RMSprop':\n",
    "    optimizer = torch.optim.RMSprop(optimizer_parameters, lr=args.learning_rate)  \n",
    "elif args.optimizer == 'Adam':\n",
    "    optimizer = torch.optim.Adam(optimizer_parameters, lr=args.learning_rate)\n",
    "elif args.optimizer == 'SGD':\n",
    "    optimizer = torch.optim.SGD(optimizer_parameters, lr=args.learning_rate, momentum=args.momentum)\n",
    "    \n",
    "# Setup scheduler\n",
    "num_train_steps = int(train_loader.__len__() / args.train_batch_size * args.epochs)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer=optimizer, \n",
    "                                            num_warmup_steps=0, \n",
    "                                            num_training_steps=num_train_steps)\n",
    "# from utils.scheduler import LRScheduler\n",
    "# scheduler = LRScheduler(optimizer = optimizer, \n",
    "#                         patience  = 10, \n",
    "#                         min_lr    = 1e-8, \n",
    "#                         factor    = 0.5, \n",
    "#                         verbose   = True)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(patience  = 20,\n",
    "                               min_delta = 0)\n",
    "\n",
    "logger.info('Training parameters were setup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert model, loaders & optimizer to fabric setup\n",
    "model, optimizer = fabric.setup(model, optimizer)\n",
    "\n",
    "train_loader = fabric.setup_dataloaders(train_loader)\n",
    "valid_loader = fabric.setup_dataloaders(valid_loader)\n",
    "test_loader = fabric.setup_dataloaders(test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]: 100%|██████████| 71/71 [00:07<00:00,  9.83it/s, AUC=0.442, accuracy=47.54%, loss=0.706]\n",
      "Validation: 100%|██████████| 8/8 [00:00<00:00, 31.37it/s, AUC=0.562, accuracy=53.12%, loss=0.69]\n",
      "Epoch [2/50]: 100%|██████████| 71/71 [00:02<00:00, 28.53it/s, AUC=0.482, accuracy=53.52%, loss=0.69] \n",
      "Validation: 100%|██████████| 8/8 [00:00<00:00, 30.33it/s, AUC=0.5, accuracy=56.25%, loss=0.682]  \n",
      "Epoch [3/50]: 100%|██████████| 71/71 [00:02<00:00, 30.38it/s, AUC=0.506, accuracy=53.87%, loss=0.692]\n",
      "Validation: 100%|██████████| 8/8 [00:00<00:00, 25.39it/s, AUC=0.469, accuracy=53.12%, loss=0.692]\n",
      "Epoch [4/50]:  28%|██▊       | 20/71 [00:00<00:01, 31.62it/s, AUC=0.488, accuracy=58.33%, loss=0.679]"
     ]
    }
   ],
   "source": [
    "best_AUC = 0\n",
    "history = {'train_loss': [], 'valid_loss': [], \n",
    "           'train_accuracy': [], 'valid_accuracy': [], \n",
    "           'train_AUC': [], 'valid_AUC': []}\n",
    "\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Activate training mode\n",
    "    model.train()\n",
    "    \n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    # setup epoch's metrics\n",
    "    metrics = {'losses': [], 'accuracy': [], 'AUC': []}\n",
    "    # initialize calculated gradients (from prev step)\n",
    "    optimizer.zero_grad()\n",
    "    for step, batch in enumerate(loop):\n",
    "        # pull all tensor batches required for training\n",
    "        text = batch['text']\n",
    "        labels = batch['labels'].to(args.device)\n",
    "        # Get loss and predictions\n",
    "        loss, predictions = model(text=text, labels=labels)      \n",
    "        # Calculate performance metrics\n",
    "        accuracy, AUC, _ = performance_evaluation(labels, predictions)\n",
    "        # extract loss - normalized\n",
    "        loss = loss / args.number_accumulated_gradients      \n",
    "        # Backpropagate errors  \n",
    "        fabric.backward(loss)\n",
    "\n",
    "        if (step+1) % args.number_accumulated_gradients == 0 or (step+1) % len(train_loader) == 0: \n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "            # Update scheduler\n",
    "            scheduler.step()\n",
    "            # Reset gradients tensors\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Add loss/accuracy/AUC\n",
    "        metrics['losses'].append(loss.item())\n",
    "        metrics['accuracy'].append(accuracy)\n",
    "        metrics['AUC'].append(AUC)\n",
    "\n",
    "\n",
    "        # add stuff to progress bar in the end\n",
    "        loop.set_description(f\"Epoch [{epoch+1}/{args.epochs}]\")\n",
    "        loop.set_postfix(loss=np.mean(metrics['losses']), accuracy=f\"{np.mean(metrics['accuracy']):.2f}%\", AUC=np.mean(metrics['AUC']))\n",
    "\n",
    "    # Calculate test loss/accuracy/AUC\n",
    "    train_loss = np.mean(metrics['losses'])\n",
    "    train_accuracy = np.mean(metrics['accuracy'])\n",
    "    train_AUC= np.mean(metrics['AUC'])\n",
    "\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(valid_loader, leave=True)\n",
    "    # setup epoch's metrics\n",
    "    metrics = {'losses': [], 'accuracy': [], 'AUC': [], 'CM': None}\n",
    "    for step, batch in enumerate(loop):\n",
    "\n",
    "        # pull all tensor batches required for training\n",
    "        text = batch['text']\n",
    "        labels = batch['labels'].to(args.device)\n",
    "        # Get loss & predictions\n",
    "        loss, predictions = model(text=text, labels=labels)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        accuracy, AUC, CM = performance_evaluation(labels, predictions)\n",
    "        # Add loss/accuracy/AUC\n",
    "        metrics['losses'].append(loss.item())\n",
    "        metrics['accuracy'].append(accuracy)\n",
    "        metrics['AUC'].append(AUC)\n",
    "        if metrics['CM'] is None: metrics['CM'] = CM \n",
    "        else: metrics['CM'] += CM\n",
    "\n",
    "        loop.set_description(\"Validation\")    \n",
    "        loop.set_postfix(loss=np.mean(metrics['losses']), accuracy=f\"{np.mean(metrics['accuracy']):.2f}%\", AUC=np.mean(metrics['AUC']))\n",
    "\n",
    "    # Calculate test loss/accuracy/AUC\n",
    "    valid_loss = np.mean(metrics['losses'])\n",
    "    valid_accuracy = np.mean(metrics['accuracy'])\n",
    "    valid_AUC= np.mean(metrics['AUC'])\n",
    "    # Elapsed time per epoch\n",
    "    elapsed = format_time(time.time() - t0)\n",
    "\n",
    "\n",
    "    # Store performance\n",
    "    history['train_loss'].append(train_loss)    \n",
    "    history['valid_loss'].append(valid_loss)\n",
    "    history['train_accuracy'].append(train_accuracy)    \n",
    "    history['valid_accuracy'].append(valid_accuracy)\n",
    "    history['train_AUC'].append(train_AUC)    \n",
    "    history['valid_AUC'].append(valid_AUC) \n",
    "\n",
    "    \n",
    "    # Update best model\n",
    "    if valid_AUC > best_AUC:\n",
    "        torch.save(model, os.path.join(args.output_dir, \"model.pt\"))\n",
    "        torch.save(model.state_dict(), os.path.join(args.output_dir, \"pytorch_model.bin\"))\n",
    "        best_AUC = valid_AUC    \n",
    "        \n",
    "    # # Learning rate scheduler\n",
    "    # scheduler(valid_loss)\n",
    "\n",
    "    # Early Stopping\n",
    "    if early_stopping(valid_loss): break    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame.from_dict(history)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 3))\n",
    "df_results[['train_accuracy','valid_accuracy']].plot(ax=ax[0], marker='o')\n",
    "df_results[['train_loss','valid_loss']].plot(ax=ax[1], marker='o')\n",
    "ax[0].legend(frameon=False, fontsize=12);\n",
    "ax[1].legend(frameon=False, fontsize=12);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load optimized model\n",
    "model = torch.load(f\"{args.output_dir}/model.pt\")\n",
    "model.eval();\n",
    "\n",
    "print('[INFO] Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(test_loader, leave=True)\n",
    "    # setup epoch's metrics\n",
    "    metrics = {'losses': [], 'accuracy': [], 'AUC': [], 'CM': 0}\n",
    "    for step, batch in enumerate(loop):\n",
    "        # pull all tensor batches required for training\n",
    "        text = batch['text']\n",
    "        labels = batch['labels'].to(args.device)\n",
    "        # Get loss & predictions\n",
    "        loss, predictions = model(text=text, labels=labels)\n",
    "        # Calculate performance metrics\n",
    "        accuracy, AUC, CM = performance_evaluation(labels, predictions)\n",
    "        \n",
    "        # Add loss/accuracy/AUC\n",
    "        metrics['losses'].append(loss.item())\n",
    "        metrics['accuracy'].append(accuracy)\n",
    "        metrics['AUC'].append(AUC)\n",
    "        if metrics['CM'] is None: metrics['CM'] = CM \n",
    "        else: metrics['CM'] += CM\n",
    "        \n",
    "        loop.set_description(\"Validation\")    \n",
    "        loop.set_postfix(loss=np.mean(metrics['losses']), accuracy=f\"{np.mean(metrics['accuracy']):.2f}%\", AUC=np.mean(metrics['AUC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loss: {np.mean(metrics['losses']):.3f}\")\n",
    "print(f\"Accuracy: {np.mean(metrics['accuracy']):.2f}%\")\n",
    "print(f\"AUC: {np.mean(metrics['AUC']):.3f}\")\n",
    "print(metrics['CM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# # Serialize JSON by converting all objects to strings\n",
    "# d = vars(args).copy()\n",
    "# d = {x:str(d[x]) for x in d.keys()}\n",
    "\n",
    "# # Store parameters\n",
    "# with open(args.output_dir + '/parameters.json', 'w') as fp:\n",
    "#     json.dump(d, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
